{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor **tf–idf** (abreviação do inglês term frequency–inverse document frequency, que significa frequência do termo–inverso da frequência nos documentos),\n",
    "é uma medida estatística que tem o intuito de indicar a importância de uma palavra de um documento em relação a uma coleção de documentos ou em um [corpus linguístico](https://pt.wikipedia.org/wiki/Corpus_lingu%C3%ADstico).\n",
    "Ela é frequentemente utilizada como fator de ponderação na recuperação de informações e na mineração de dados.\n",
    "\n",
    "O valor **tf–idf** de uma palavra aumenta proporcionalmente à medida que aumenta o número de ocorrências dela em um documento, no entanto, esse valor é equilibrado pela \n",
    "frequência da palavra no corpus. Isso auxilia a distinguir o fato da ocorrência de algumas palavras serem geralmente mais comuns que outras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência do termo (tf)\n",
    "\n",
    "Suponha que foram selecionados uma coleção de documento de textos em português e que nós desejamos determinar qual deles tem maior relação com a frase \"uma vaca amarela\". Uma maneira simples de iniciar essa análise seria simplesmente descartar todos os documentos que não contém as palavras \"uma\", \"vaca\" e \"amarela\", mas apenas esse procedimento não seria suficiente para completar a análise, pois muitos documentos provavelmente possuem as três palavras. Assim, para melhorar a distinção entre elas, nós podemos **contar o número de vezes que um dos termos ocorre em cada documento e somar esse valor; o número de vezes que um termo ocorre em um documento é a frequência do termo**.\n",
    "\n",
    "A primeira forma de ponderação de termos é atribuída a Hans Peter Luhn (1957) e se baseia na suposição de Luhn:\n",
    "\n",
    "- O peso de um termo que ocorre em um documento é diretamente proporcional à sua frequência.\n",
    "\n",
    "TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img  src=\"tf.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverso da frequência nos documentos (idf)\n",
    "No entanto, como o termo \"uma\" é muito comum, isso vai dar ênfase em documentos que utilizam essa palavra com mais frequência, sem dar a ênfase apropriada para termos com mais \n",
    "significado como \"vaca\" e \"amarela\". O termo \"uma\" não é uma boa palavra-chave para distinguir documentos relevantes de não-relevantes em comparação com as palavras \"vaca\" e \"amarela\". \n",
    "Assim, o inverso da frequência do termo nos documentos é incorporado para diminuir o peso dos termos que ocorrem mais frequentemente no conjunto de textos selecionados, ao mesmo tempo\n",
    "que aumenta o peso daqueles que ocorrem raramente.\n",
    "\n",
    "Karen Spärck Jones (1972) concebeu uma interpretação estatística do termo **IDF**, que se tornou um conceito base para a ponderação de termos:\n",
    "\n",
    "- A especificidade de um termo pode ser quantificada por uma função inversa do número de documentos em que ele ocorre.\n",
    "\n",
    "IDF: (Total number of sentences (documents))/(Number of sentences (documents) containing the word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img  src=\"idf.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Pseudocódigo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"460\" height=\"300\" src=\"pseudocode.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"formula.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'this is the first document pipoca pipoca pipoca',\n",
    "    'this document is the second document pipoca pipoca pipoca',\n",
    "    'and this is the third one pipoca pipoca pipoca',\n",
    "    'as this the first document amesterda'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "docA = 'this is the first document pipoca pipoca pipoca'\n",
    "docB = 'this document is the second document pipoca pipoca pipoca'\n",
    "docC = 'and this is the third one pipoca pipoca pipoca'\n",
    "docD = 'as this the first document'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordSet = set()\n",
    "# for doc in corpus:\n",
    "#     wordSet= wordSet.union(set(doc.split(\" \")))\n",
    "    \n",
    "bowA = docA.split(\" \")\n",
    "bowB = docB.split(\" \")\n",
    "bowC = docC.split(\" \")\n",
    "bowD = docD.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSet = set(bowA).union(set(bowB)).union(set(bowC)).union(set(bowD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and',\n",
       " 'as',\n",
       " 'document',\n",
       " 'first',\n",
       " 'is',\n",
       " 'one',\n",
       " 'pipoca',\n",
       " 'second',\n",
       " 'the',\n",
       " 'third',\n",
       " 'this'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "wordDictB = dict.fromkeys(wordSet, 0)\n",
    "wordDictC = dict.fromkeys(wordSet, 0)\n",
    "wordDictD = dict.fromkeys(wordSet, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 0,\n",
       " 'third': 0,\n",
       " 'second': 0,\n",
       " 'as': 0,\n",
       " 'pipoca': 0,\n",
       " 'first': 0,\n",
       " 'and': 0,\n",
       " 'this': 0,\n",
       " 'document': 0,\n",
       " 'is': 0,\n",
       " 'the': 0}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in bowA:\n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in bowB:\n",
    "    wordDictB[word]+=1\n",
    "    \n",
    "for word in bowC:\n",
    "    wordDictC[word]+=1\n",
    "    \n",
    "for word in bowD:\n",
    "    wordDictD[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 0,\n",
       " 'third': 0,\n",
       " 'second': 0,\n",
       " 'as': 0,\n",
       " 'pipoca': 3,\n",
       " 'first': 1,\n",
       " 'and': 0,\n",
       " 'this': 1,\n",
       " 'document': 1,\n",
       " 'is': 1,\n",
       " 'the': 1}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  as  document  first  is  one  pipoca  second  the  third  this\n",
       "0    0   0         1      1   1    0       3       0    1      0     1\n",
       "1    0   0         2      0   1    0       3       1    1      0     1\n",
       "2    1   0         0      0   1    1       3       0    1      1     1\n",
       "3    0   1         1      1   0    0       0       0    1      0     1"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([wordDictA, wordDictB, wordDictC, wordDictD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    import math\n",
    "    \"\"\"\n",
    "    TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)\n",
    "    \"\"\"\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(bowCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfBowA = computeTF(wordDictA, bowA)\n",
    "tfBowB = computeTF(wordDictB, bowB)\n",
    "tfBowC = computeTF(wordDictC, bowC)\n",
    "tfBowD = computeTF(wordDictD, bowD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one': 0.0,\n",
       " 'third': 0.0,\n",
       " 'second': 0.0,\n",
       " 'as': 0.0,\n",
       " 'pipoca': 0.375,\n",
       " 'first': 0.125,\n",
       " 'and': 0.0,\n",
       " 'this': 0.125,\n",
       " 'document': 0.125,\n",
       " 'is': 0.125,\n",
       " 'the': 0.125}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfBowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(docList):\n",
    "    \"\"\"\n",
    "    IDF: (Total number of sentences (documents))/(Number of sentences (documents) containing the word)\n",
    "    \"\"\"\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for doc in docList:\n",
    "        for word, val in doc.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val) ) +1\n",
    "        print(f\"word: {word},val: {val}, IDF: {idfDict[word]}\")\n",
    "        \n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: one,val: 1, IDF: 1.6020599913279625\n",
      "word: third,val: 1, IDF: 1.6020599913279625\n",
      "word: second,val: 1, IDF: 1.6020599913279625\n",
      "word: as,val: 1, IDF: 1.6020599913279625\n",
      "word: pipoca,val: 3, IDF: 1.1249387366083\n",
      "word: first,val: 2, IDF: 1.3010299956639813\n",
      "word: and,val: 1, IDF: 1.6020599913279625\n",
      "word: this,val: 4, IDF: 1.0\n",
      "word: document,val: 3, IDF: 1.1249387366083\n",
      "word: is,val: 3, IDF: 1.1249387366083\n",
      "word: the,val: 4, IDF: 1.0\n"
     ]
    }
   ],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB, wordDictC, wordDictD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        print(f\"word :{word} , TF :{val}, IDF: {idfs[word]}\")\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word :one , TF :0.0, IDF: 1.6020599913279625\n",
      "word :third , TF :0.0, IDF: 1.6020599913279625\n",
      "word :second , TF :0.0, IDF: 1.6020599913279625\n",
      "word :as , TF :0.0, IDF: 1.6020599913279625\n",
      "word :pipoca , TF :0.375, IDF: 1.1249387366083\n",
      "word :first , TF :0.125, IDF: 1.3010299956639813\n",
      "word :and , TF :0.0, IDF: 1.6020599913279625\n",
      "word :this , TF :0.125, IDF: 1.0\n",
      "word :document , TF :0.125, IDF: 1.1249387366083\n",
      "word :is , TF :0.125, IDF: 1.1249387366083\n",
      "word :the , TF :0.125, IDF: 1.0\n",
      "word :one , TF :0.0, IDF: 1.6020599913279625\n",
      "word :third , TF :0.0, IDF: 1.6020599913279625\n",
      "word :second , TF :0.1111111111111111, IDF: 1.6020599913279625\n",
      "word :as , TF :0.0, IDF: 1.6020599913279625\n",
      "word :pipoca , TF :0.3333333333333333, IDF: 1.1249387366083\n",
      "word :first , TF :0.0, IDF: 1.3010299956639813\n",
      "word :and , TF :0.0, IDF: 1.6020599913279625\n",
      "word :this , TF :0.1111111111111111, IDF: 1.0\n",
      "word :document , TF :0.2222222222222222, IDF: 1.1249387366083\n",
      "word :is , TF :0.1111111111111111, IDF: 1.1249387366083\n",
      "word :the , TF :0.1111111111111111, IDF: 1.0\n",
      "word :one , TF :0.1111111111111111, IDF: 1.6020599913279625\n",
      "word :third , TF :0.1111111111111111, IDF: 1.6020599913279625\n",
      "word :second , TF :0.0, IDF: 1.6020599913279625\n",
      "word :as , TF :0.0, IDF: 1.6020599913279625\n",
      "word :pipoca , TF :0.3333333333333333, IDF: 1.1249387366083\n",
      "word :first , TF :0.0, IDF: 1.3010299956639813\n",
      "word :and , TF :0.1111111111111111, IDF: 1.6020599913279625\n",
      "word :this , TF :0.1111111111111111, IDF: 1.0\n",
      "word :document , TF :0.0, IDF: 1.1249387366083\n",
      "word :is , TF :0.1111111111111111, IDF: 1.1249387366083\n",
      "word :the , TF :0.1111111111111111, IDF: 1.0\n",
      "word :one , TF :0.0, IDF: 1.6020599913279625\n",
      "word :third , TF :0.0, IDF: 1.6020599913279625\n",
      "word :second , TF :0.0, IDF: 1.6020599913279625\n",
      "word :as , TF :0.2, IDF: 1.6020599913279625\n",
      "word :pipoca , TF :0.0, IDF: 1.1249387366083\n",
      "word :first , TF :0.2, IDF: 1.3010299956639813\n",
      "word :and , TF :0.0, IDF: 1.6020599913279625\n",
      "word :this , TF :0.2, IDF: 1.0\n",
      "word :document , TF :0.2, IDF: 1.1249387366083\n",
      "word :is , TF :0.0, IDF: 1.1249387366083\n",
      "word :the , TF :0.2, IDF: 1.0\n"
     ]
    }
   ],
   "source": [
    "tfidfBowA = computeTFIDF(tfBowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfBowB, idfs)\n",
    "tfidfBowC = computeTFIDF(tfBowC, idfs)\n",
    "tfidfBowD = computeTFIDF(tfBowD, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140617</td>\n",
       "      <td>0.162629</td>\n",
       "      <td>0.140617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.374980</td>\n",
       "      <td>0.178007</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.178007</td>\n",
       "      <td>0.374980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.178007</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320412</td>\n",
       "      <td>0.224988</td>\n",
       "      <td>0.260206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and        as  document     first        is       one    pipoca  \\\n",
       "0  0.000000  0.000000  0.140617  0.162629  0.140617  0.000000  0.421852   \n",
       "1  0.000000  0.000000  0.249986  0.000000  0.124993  0.000000  0.374980   \n",
       "2  0.178007  0.000000  0.000000  0.000000  0.124993  0.178007  0.374980   \n",
       "3  0.000000  0.320412  0.224988  0.260206  0.000000  0.000000  0.000000   \n",
       "\n",
       "     second       the     third      this  \n",
       "0  0.000000  0.125000  0.000000  0.125000  \n",
       "1  0.178007  0.111111  0.000000  0.111111  \n",
       "2  0.000000  0.111111  0.178007  0.111111  \n",
       "3  0.000000  0.200000  0.000000  0.200000  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([tfidfBowA, tfidfBowB, tfidfBowC , tfidfBowD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tfidf():\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        '''adicione os parâmetros necessários no __init__'''\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        '''NÃO ALTERE OS PARÂMETROS DO MÉTODO FIT'''\n",
    "        pass\n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''NÃO ALTERE OS PARÂMETROS DO MÉTODO PREDICT'''        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com o Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'this is the first document pipoca pipoca pipoca',\n",
    "    'this document is the second document pipoca pipoca pipoca',\n",
    "    'and this is the third one pipoca pipoca pipoca',\n",
    "    'as this the first document'\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "vectorizer.get_feature_names()[:5]\n",
    "\n",
    "import numpy\n",
    "\n",
    "features_array = numpy.array(vectorizer.get_feature_names())\n",
    "features_array[:5]\n",
    "\n",
    "data = X.todense().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>as</th>\n",
       "      <th>document</th>\n",
       "      <th>first</th>\n",
       "      <th>is</th>\n",
       "      <th>one</th>\n",
       "      <th>pipoca</th>\n",
       "      <th>second</th>\n",
       "      <th>the</th>\n",
       "      <th>third</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268583</td>\n",
       "      <td>0.331753</td>\n",
       "      <td>0.268583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.805749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711241</td>\n",
       "      <td>0.371432</td>\n",
       "      <td>0.193829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231246</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.693738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189059</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>0.189059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623342</td>\n",
       "      <td>0.397871</td>\n",
       "      <td>0.491450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and        as  document     first        is       one    pipoca  \\\n",
       "0  0.000000  0.000000  0.268583  0.331753  0.268583  0.000000  0.805749   \n",
       "1  0.000000  0.000000  0.474161  0.000000  0.237080  0.000000  0.711241   \n",
       "2  0.362292  0.000000  0.000000  0.000000  0.231246  0.362292  0.693738   \n",
       "3  0.000000  0.623342  0.397871  0.491450  0.000000  0.000000  0.000000   \n",
       "\n",
       "     second       the     third      this  \n",
       "0  0.000000  0.219584  0.000000  0.219584  \n",
       "1  0.371432  0.193829  0.000000  0.193829  \n",
       "2  0.000000  0.189059  0.362292  0.189059  \n",
       "3  0.000000  0.325285  0.000000  0.325285  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.DataFrame(data, columns=features_array)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['document', 'first', 'is', 'the', 'this']\n",
      "['document', 'is', 'second', 'the', 'this']\n",
      "['and', 'is', 'one', 'the', 'third', 'this']\n",
      "['document', 'first', 'the', 'this']\n"
     ]
    }
   ],
   "source": [
    "for i in df.iterrows():\n",
    "    values = i[1].values.tolist()\n",
    "    print([features_array[i] for i, v in enumerate(values) if 0.0 < v < 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com o Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|label|sentence                                                 |words                                                              |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+\n",
      "|0.0  |this is the first document pipoca pipoca pipoca          |[this, is, the, first, document, pipoca, pipoca, pipoca]           |\n",
      "|0.0  |this document is the second document pipoca pipoca pipoca|[this, document, is, the, second, document, pipoca, pipoca, pipoca]|\n",
      "|1.0  |and this is the third one pipoca pipoca pipoca           |[and, this, is, the, third, one, pipoca, pipoca, pipoca]           |\n",
      "|1.0  |as this the first document                               |[as, this, the, first, document]                                   |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer,CountVectorizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.appName('abc').getOrCreate()\n",
    "\n",
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, 'this is the first document pipoca pipoca pipoca'),\n",
    "    (0.0, 'this document is the second document pipoca pipoca pipoca'),\n",
    "    (1.0, 'and this is the third one pipoca pipoca pipoca'),\n",
    "    (1.0, 'as this the first document')\n",
    "    \n",
    "], [\"label\", \"sentence\"])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "wordsData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+\n",
      "|label|sentence                                                 |words                                                              |cv_features                                       |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+\n",
      "|0.0  |this is the first document pipoca pipoca pipoca          |[this, is, the, first, document, pipoca, pipoca, pipoca]           |(11,[0,1,2,3,4,5],[3.0,1.0,1.0,1.0,1.0,1.0])      |\n",
      "|0.0  |this document is the second document pipoca pipoca pipoca|[this, document, is, the, second, document, pipoca, pipoca, pipoca]|(11,[0,1,2,3,4,8],[3.0,2.0,1.0,1.0,1.0,1.0])      |\n",
      "|1.0  |and this is the third one pipoca pipoca pipoca           |[and, this, is, the, third, one, pipoca, pipoca, pipoca]           |(11,[0,2,3,4,6,7,9],[3.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|1.0  |as this the first document                               |[as, this, the, first, document]                                   |(11,[1,2,3,5,10],[1.0,1.0,1.0,1.0,1.0])           |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"cv_features\") #vocabSize=3, minDF=2.0\n",
    "model = cv.fit(wordsData)\n",
    "\n",
    "featurizedData = model.transform(wordsData)\n",
    "featurizedData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pipoca', 'document', 'the', 'this', 'is', 'first', 'one', 'third', 'second', 'and', 'as']\n"
     ]
    }
   ],
   "source": [
    "print(model.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- cv_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurizedData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+----+---+-----+---+-----+------+---+---+\n",
      "|pipoca|document|the|this| is|first|one|third|second|and| as|\n",
      "+------+--------+---+----+---+-----+---+-----+------+---+---+\n",
      "|   3.0|     1.0|1.0| 1.0|1.0|  1.0|0.0|  0.0|   0.0|0.0|0.0|\n",
      "|   3.0|     2.0|1.0| 1.0|1.0|  0.0|0.0|  0.0|   1.0|0.0|0.0|\n",
      "|   3.0|     0.0|1.0| 1.0|1.0|  0.0|1.0|  1.0|   0.0|1.0|0.0|\n",
      "|   0.0|     1.0|1.0| 1.0|0.0|  1.0|0.0|  0.0|   0.0|0.0|1.0|\n",
      "+------+--------+---+----+---+-----+---+-----+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_udf = udf(lambda vector: vector.toArray().tolist(),ArrayType(DoubleType()))\n",
    "\n",
    "colvalues = rescaledData.select(vector_udf('cv_features').alias('features')).collect()\n",
    "\n",
    "spark.createDataFrame(list(map(lambda x:x.features,colvalues)),model.vocabulary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|sentence                                                 |words                                                              |cv_features                                       |idf_features                                                                                                                  |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |this is the first document pipoca pipoca pipoca          |[this, is, the, first, document, pipoca, pipoca, pipoca]           |(11,[0,1,2,3,4,5],[3.0,1.0,1.0,1.0,1.0,1.0])      |(11,[0,1,2,3,4,5],[0.6694306539426294,0.22314355131420976,0.0,0.0,0.22314355131420976,0.5108256237659907])                    |\n",
      "|0.0  |this document is the second document pipoca pipoca pipoca|[this, document, is, the, second, document, pipoca, pipoca, pipoca]|(11,[0,1,2,3,4,8],[3.0,2.0,1.0,1.0,1.0,1.0])      |(11,[0,1,2,3,4,8],[0.6694306539426294,0.44628710262841953,0.0,0.0,0.22314355131420976,0.9162907318741551])                    |\n",
      "|1.0  |and this is the third one pipoca pipoca pipoca           |[and, this, is, the, third, one, pipoca, pipoca, pipoca]           |(11,[0,2,3,4,6,7,9],[3.0,1.0,1.0,1.0,1.0,1.0,1.0])|(11,[0,2,3,4,6,7,9],[0.6694306539426294,0.0,0.0,0.22314355131420976,0.9162907318741551,0.9162907318741551,0.9162907318741551])|\n",
      "|1.0  |as this the first document                               |[as, this, the, first, document]                                   |(11,[1,2,3,5,10],[1.0,1.0,1.0,1.0,1.0])           |(11,[1,2,3,5,10],[0.22314355131420976,0.0,0.0,0.5108256237659907,0.9162907318741551])                                         |\n",
      "+-----+---------------------------------------------------------+-------------------------------------------------------------------+--------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"cv_features\", outputCol=\"idf_features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+---+----+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|            pipoca|           document|the|this|                 is|             first|               one|             third|            second|               and|                as|\n",
      "+------------------+-------------------+---+----+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|0.6694306539426294|0.22314355131420976|0.0| 0.0|0.22314355131420976|0.5108256237659907|               0.0|               0.0|               0.0|               0.0|               0.0|\n",
      "|0.6694306539426294|0.44628710262841953|0.0| 0.0|0.22314355131420976|               0.0|               0.0|               0.0|0.9162907318741551|               0.0|               0.0|\n",
      "|0.6694306539426294|                0.0|0.0| 0.0|0.22314355131420976|               0.0|0.9162907318741551|0.9162907318741551|               0.0|0.9162907318741551|               0.0|\n",
      "|               0.0|0.22314355131420976|0.0| 0.0|                0.0|0.5108256237659907|               0.0|               0.0|               0.0|               0.0|0.9162907318741551|\n",
      "+------------------+-------------------+---+----+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "colvalues = rescaledData.select(vector_udf('idf_features').alias('features')).collect()\n",
    "\n",
    "spark.createDataFrame(list(map(lambda x:x.features,colvalues)),model.vocabulary).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/how-sklearns-tf-idf-is-different-from-the-standard-tf-idf-275fa582e73d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/4494134497577204/2690176961360097/6933319862459084/latest.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/39546671/handle-unseen-categorical-string-spark-countvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://codelabs.developers.google.com/codelabs/spark-nlp/#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
